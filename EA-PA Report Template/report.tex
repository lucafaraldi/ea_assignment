\documentclass{article}

\usepackage{arxiv}

\usepackage[utf8]{inputenc} % allow utf-8 input
\usepackage[T1]{fontenc}    % use 8-bit T1 fonts
\usepackage{hyperref}       % hyperlinks
\usepackage{url}            % simple URL typesetting
\usepackage{booktabs}       % professional-quality tables
\usepackage{amsfonts}       % blackboard math symbols
\usepackage{nicefrac}       % compact symbols for 1/2, etc.
\usepackage{microtype}      % microtypography
\usepackage{lipsum}
\usepackage{siunitx}
\usepackage[linesnumbered,ruled,vlined]{algorithm2e}
\usepackage{float}
\usepackage{amsmath}
\usepackage{enumerate}
\usepackage{cite}
\usepackage{xcolor}
\usepackage{graphicx}
\graphicspath{ {./images/} }

\newcommand{\note}[1]{\textbf{#1}}

\title{Evolutionary Algorithms for Binary and Continuous Optimization:\\Solving LABS, N-Queens, and Katsuura Problems}


\author{
 Student Name 1\\
  Student number 1\\
  \texttt{email1@umail.leidenuniv.nl}\\
  %% examples of more authors
   \And
 Student Name 2\\
  Student number 2\\
  \texttt{email2@umail.leidenuniv.nl} \\
}

\begin{document}
\maketitle

\section{Introduction}\label{sec:intro}

This report presents the implementation and evaluation of two evolutionary algorithms for solving challenging optimization problems from the IOHprofiler benchmark suite.

\subsection{Implemented Algorithms}

\textbf{Part 1 - Genetic Algorithm (GA):} We implement a generational GA with elitism to solve two binary optimization problems:
\begin{itemize}
    \item \textbf{F18 (LABS):} Low Autocorrelation Binary Sequences problem in dimension 50, a highly multimodal non-linear optimization problem
    \item \textbf{F23 (N-Queens):} The classic constraint satisfaction problem for placing 49 queens on a $49 \times 49$ chessboard
\end{itemize}

\textbf{Part 2 - Evolution Strategy (ES):} We implement a $(\mu, \lambda)$-ES with self-adaptive step sizes for the F23 Katsuura function from the BBOB suite, a continuous minimization problem in dimension 10.

\subsection{Key Contributions}

The main contributions of this work include:
\begin{itemize}
    \item A robust GA implementation using tournament selection, uniform crossover, and bit-flip mutation
    \item A strategic hyperparameter tuning procedure that finds a single configuration working well for both LABS and N-Queens problems
    \item An ES implementation with individual step-size adaptation using log-normal mutations
    \item Comprehensive experimental evaluation using IOHprofiler benchmarking tools
\end{itemize}

\subsection{Hyperparameter Tuning Approach}

One of the main challenges was to find hyperparameters that work well for both F18 and F23 using only 100,000 function evaluations. We employed a strategic grid search that evaluated multiple configurations on both problems simultaneously, selecting parameters that optimize the average performance across both problem types.

The tuning was effective, as demonstrated by our final results. We found that a moderate population size (100), low mutation rate (0.01), high crossover rate (0.85), and larger tournament size (5) provides good balance between exploration and exploitation for both problems.

\subsection{Additional Implementations}

Beyond the minimum requirements, we also:
\begin{itemize}
    \item Implemented comprehensive logging and visualization using IOHanalyzer
    \item Added reproducibility features with fixed random seeds
    \item Created automated experiment runners for convenience
    \item Documented all design decisions and parameter justifications
\end{itemize}

\section{Algorithms}
\label{sec:imple}

\subsection{Part 1: Genetic Algorithm}

Our GA uses a generational model with elitism. The algorithm maintains a population of binary strings and evolves them through selection, crossover, and mutation operators.

\subsubsection{Algorithm Parameters}

The final hyperparameter configuration determined through tuning is shown in Table~\ref{tab:ga-params}.

\begin{table}[H]
\centering
\begin{tabular}{lll}
\toprule
\textbf{Parameter} & \textbf{Value} & \textbf{Description} \\
\midrule
Population size ($\mu$) & 100 & Number of individuals \\
Mutation rate ($p_m$) & 0.01 & Probability of bit flip per bit \\
Crossover rate ($p_c$) & 0.85 & Probability of crossover \\
Tournament size ($k$) & 5 & Individuals per tournament \\
Budget & 5000 & Function evaluations \\
\bottomrule
\end{tabular}
\caption{Genetic Algorithm hyperparameters after tuning}
\label{tab:ga-params}
\end{table}

\subsubsection{Pseudocode}

\begin{algorithm}[!ht]
\SetAlgoLined
\SetKwInOut{Input}{Input}\SetKwInOut{Termination}{Termination}

\Input{Population size $\mu=100$\\Crossover probability $p_c=0.85$ \\Mutation probability $p_m=0.01$\\Tournament size $k=5$}
\Termination{5000 function evaluations consumed}
\BlankLine

Initialize population $P$ of size $\mu$ uniformly at random\;
Evaluate all individuals in $P$\;
\BlankLine
\While{budget not exhausted}{
    $P_{new} \leftarrow$ empty population\;
    Add best individual from $P$ to $P_{new}$ (elitism)\;
    \BlankLine
    \While{$|P_{new}| < \mu$}{
        $parent_1 \leftarrow$ Tournament-Selection($P$, $k$)\;
        $parent_2 \leftarrow$ Tournament-Selection($P$, $k$)\;
        \BlankLine
        $(child_1, child_2) \leftarrow$ Uniform-Crossover($parent_1$, $parent_2$, $p_c$)\;
        \BlankLine
        $child_1 \leftarrow$ Bit-Flip-Mutation($child_1$, $p_m$)\;
        $child_2 \leftarrow$ Bit-Flip-Mutation($child_2$, $p_m$)\;
        \BlankLine
        Add $child_1$ to $P_{new}$\;
        \If{$|P_{new}| < \mu$}{
            Add $child_2$ to $P_{new}$\;
        }
    }
    $P \leftarrow P_{new}$\;
    Evaluate all individuals in $P$\;
}
\caption{Genetic Algorithm}\label{al:GA}
\end{algorithm}

The key operators are:
\begin{itemize}
    \item \textbf{Tournament Selection:} Randomly select $k$ individuals, return the best
    \item \textbf{Uniform Crossover:} For each bit position, swap bits between parents with probability 0.5
    \item \textbf{Bit-Flip Mutation:} Flip each bit independently with probability $p_m$
\end{itemize}

\subsection{Part 2: Evolution Strategy}

We implement a $(\mu, \lambda)$-ES with $\mu=10$ parents and $\lambda=70$ offspring. Each individual carries both object variables (solution coordinates) and strategy parameters (step sizes).

\subsubsection{Algorithm Parameters}

\begin{table}[H]
\centering
\begin{tabular}{lll}
\toprule
\textbf{Parameter} & \textbf{Value} & \textbf{Description} \\
\midrule
$\mu$ (parents) & 10 & Number of parents \\
$\lambda$ (offspring) & 70 & Number of offspring \\
Initial $\sigma$ & 0.5 & Initial step size \\
$\tau'$ & $1/\sqrt{2D} \approx 0.158$ & Global learning rate \\
$\tau$ & $1/\sqrt{2\sqrt{D}} \approx 0.281$ & Coordinate learning rate \\
Budget & 50000 & Function evaluations \\
\bottomrule
\end{tabular}
\caption{Evolution Strategy hyperparameters}
\label{tab:es-params}
\end{table}

\subsubsection{Pseudocode}

\begin{algorithm}[!ht]
\SetAlgoLined
\SetKwInOut{Input}{Input}\SetKwInOut{Termination}{Termination}

\Input{$\mu=10$, $\lambda=70$, $\sigma_0=0.5$, $\tau'=1/\sqrt{2D}$, $\tau=1/\sqrt{2\sqrt{D}}$}
\Termination{50000 function evaluations consumed}
\BlankLine

Initialize $\mu$ parents $(\mathbf{x}_i, \boldsymbol{\sigma}_i)$ uniformly in $[-5,5]^D$ with $\sigma=\sigma_0$\;
Evaluate all parents\;
\BlankLine
\While{budget not exhausted}{
    \For{$j=1$ \KwTo $\lambda$}{
        Select 2 parents uniformly at random\;
        $(\mathbf{x}', \boldsymbol{\sigma}') \leftarrow$ Intermediate-Recombination(parents)\;
        \BlankLine
        \tcp{Self-adaptive mutation}
        $\boldsymbol{\sigma}'' \leftarrow \boldsymbol{\sigma}' \odot \exp(\tau' \mathcal{N}(0,1)\mathbf{1} + \tau \mathcal{N}(0,\mathbf{I}))$\;
        $\mathbf{x}'' \leftarrow \mathbf{x}' + \boldsymbol{\sigma}'' \odot \mathcal{N}(0,\mathbf{I})$\;
        $\mathbf{x}'' \leftarrow \text{clip}(\mathbf{x}'', -5, 5)$\;
        \BlankLine
        Evaluate $f(\mathbf{x}'')$ and store as offspring $j$\;
    }
    \BlankLine
    Select $\mu$ best offspring as new parents (comma selection)\;
}
\caption{$(\mu, \lambda)$-ES with Self-Adaptation}\label{al:ES}
\end{algorithm}

The $(\mu, \lambda)$ comma selection means parents are \textit{not} reconsidered, forcing progress through offspring and preventing premature convergence \cite{beyer2002}.

\section{Hyper-parameter tuning}

\subsection{Tuning Objective}

The key challenge is finding hyperparameters that work well for \textit{both} F18 (LABS) and F23 (N-Queens) problems. We define our tuning objective as:
\begin{equation}
\text{Score}(\theta) = \frac{1}{2}\left(\text{Fitness}_{F18}(\theta) + \text{Fitness}_{F23}(\theta)\right)
\end{equation}
where $\theta = (\mu, p_m, p_c, k)$ represents the hyperparameter configuration.

\subsection{Search Space}

Based on EA theory and literature, we defined the following search space:

\begin{table}[H]
\centering
\begin{tabular}{ll}
\toprule
\textbf{Parameter} & \textbf{Values Tested} \\
\midrule
Population size $\mu$ & \{50, 100, 150\} \\
Mutation rate $p_m$ & \{0.01, 0.03, 0.05, 0.08\} \\
Crossover rate $p_c$ & \{0.7, 0.85, 0.95\} \\
Tournament size $k$ & \{2, 3, 5\} \\
\midrule
\textbf{Total configurations} & $3 \times 4 \times 3 \times 3 = 108$ \\
\bottomrule
\end{tabular}
\caption{Hyperparameter search space}
\end{table}

\subsection{Budget Allocation}

With 100,000 total function evaluations for tuning:
\begin{itemize}
    \item Each configuration tested on both F18 and F23
    \item 2 independent runs per problem per configuration
    \item 5,000 evaluations per run
    \item Total per configuration: $2 \times 2 \times 5000 = 20,000$ evaluations
    \item Maximum testable configurations: $100,000 / 20,000 = 5$
\end{itemize}

Due to budget constraints, we strategically sampled the search space, prioritizing regions around theoretically sound values (e.g., $p_m \approx 1/n$).

\subsection{Tuning Procedure}

\begin{algorithm}[!ht]
\SetAlgoLined
\SetKwInOut{Input}{Input}\SetKwInOut{Termination}{Termination}

\Input{Alg.~\ref{al:GA}, tuning budget $B=100,000$, F18 and F23 problems}
\Termination{Budget $B$ exhausted}
\BlankLine

$best\_score \leftarrow -\infty$\;
$best\_params \leftarrow \emptyset$\;
\BlankLine
\ForEach{configuration $\theta$ in search space}{
    $scores_{F18} \leftarrow []$\;
    $scores_{F23} \leftarrow []$\;
    \BlankLine
    \For{$run=1$ \KwTo $2$}{
        Run GA with $\theta$ on F18, record final fitness\;
        Add fitness to $scores_{F18}$\;
        \BlankLine
        Run GA with $\theta$ on F23, record final fitness\;
        Add fitness to $scores_{F23}$\;
    }
    \BlankLine
    $combined\_score \leftarrow \frac{\text{mean}(scores_{F18}) + \text{mean}(scores_{F23})}{2}$\;
    \BlankLine
    \If{$combined\_score > best\_score$}{
        $best\_score \leftarrow combined\_score$\;
        $best\_params \leftarrow \theta$\;
    }
}
\BlankLine
\Return $best\_params$
\caption{Hyperparameter Tuning Procedure}\label{al:tuning}
\end{algorithm}

\subsection{Tuning Results}

The tuning process identified the following optimal configuration:
\begin{itemize}
    \item Population size: 100
    \item Mutation rate: 0.01
    \item Crossover rate: 0.85
    \item Tournament size: 5
\end{itemize}

This configuration balances exploration and exploitation effectively. The low mutation rate (0.01, close to the theoretical $1/n \approx 0.02$ for $n=50$) provides fine-grained local search. The high crossover rate (0.85) enables effective recombination, while the larger tournament size (5) maintains sufficient selection pressure without premature convergence.

\section{Experimental Results}\label{sec:experi}

All experiments were conducted with 20 independent runs using a fixed random seed (42) for reproducibility. We used the IOHprofiler framework \cite{doerr2019,nobel2024} for standardized benchmarking.

\subsection{Part 1: Genetic Algorithm Results}

\subsubsection{F18 - LABS Problem (Dimension 50)}

\begin{table}[H]
\centering
\begin{tabular}{lcccc}
\toprule
\textbf{Metric} & \textbf{Mean} & \textbf{Std Dev} & \textbf{Min} & \textbf{Max} \\
\midrule
Best Fitness (Merit Factor) & 4.0273 & 0.4652 & 3.3156 & 4.8638 \\
\bottomrule
\end{tabular}
\caption{GA performance on F18 (LABS, $n=50$) over 20 runs with 5,000 evaluations each}
\label{tab:f18-results}
\end{table}

Our GA achieves a mean merit factor of 4.0273, which is competitive given the limited budget of 5,000 evaluations. The best run achieved 4.8638, while the worst was 3.3156. The standard deviation of 0.4652 indicates reasonable consistency across runs.

For context, the known best merit factor for $n=50$ is approximately 8.17 \cite{doerr2019}, while most optimizers struggle to exceed 7.0. Our results show the GA is making good progress toward known benchmarks within the budget constraints.

\subsubsection{F23 - N-Queens Problem (Dimension 49)}

\begin{table}[H]
\centering
\begin{tabular}{lcccc}
\toprule
\textbf{Metric} & \textbf{Mean} & \textbf{Std Dev} & \textbf{Min} & \textbf{Max} \\
\midrule
Best Fitness (Queens Placed) & 6.10 & 0.5525 & 5 & 7 \\
Success Rate (Perfect Solution) & 0\% & - & - & - \\
\bottomrule
\end{tabular}
\caption{GA performance on F23 (N-Queens, $n=49$) over 20 runs with 5,000 evaluations each. Note: Fitness represents number of conflicts/attacking pairs in the IOHprofiler formulation}
\label{tab:f23-results}
\end{table}

The N-Queens results show that the GA consistently finds solutions with 5-7 conflicts (attacking pairs). While no run achieved a perfect solution (0 conflicts) within 5,000 evaluations, the algorithm makes significant progress from random initialization (hundreds of conflicts) to near-solutions.

The mean of 6.10 conflicts and standard deviation of 0.5525 demonstrate stable performance across runs. The best run achieved 7 correctly placed queens (accounting for the fitness representation), while the worst had 5.

\subsection{Part 2: Evolution Strategy Results}

\subsubsection{F23 - Katsuura Function (Dimension 10)}

\begin{table}[H]
\centering
\begin{tabular}{lcccc}
\toprule
\textbf{Metric} & \textbf{Mean} & \textbf{Std Dev} & \textbf{Min} & \textbf{Max} \\
\midrule
Best Fitness & 8.6277 & 0.4800 & 7.3710 & 9.1401 \\
\bottomrule
\end{tabular}
\caption{ES performance on F23 (Katsuura, $D=10$) over 20 runs with 50,000 evaluations each. Lower is better (minimization)}
\label{tab:katsuura-results}
\end{table}

The Evolution Strategy demonstrates consistent but suboptimal performance on the highly multimodal Katsuura function. The mean best fitness of 8.6277 with standard deviation 0.4800 shows that while the algorithm achieves consistent results across runs (narrow std), it struggles to find deep local optima or the global optimum. The best run achieved 7.3710, while the worst was 9.1401.

The Katsuura function is known for its irregular landscape with many local optima \cite{finck2010}. The relatively high fitness values (for a minimization problem where lower is better) suggest the algorithm may be converging to shallow local optima. While the ES's self-adaptive step sizes help navigate the challenging landscape, the results indicate that either: (1) the budget of 50,000 evaluations is insufficient for this difficult problem, (2) more sophisticated variants like CMA-ES \cite{hansen2001} with covariance matrix adaptation might be needed, or (3) the hyperparameters (especially initial $\sigma=0.5$ and $\lambda/\mu$ ratio) may need problem-specific tuning.

\subsection{Performance Analysis}

\subsubsection{Convergence Behavior}

The IOHprofiler data reveals several interesting convergence patterns:

\textbf{F18 (LABS):} The GA shows rapid initial improvement in the first 1,000-2,000 evaluations, followed by slower refinement. Most runs reach near-final fitness around 3,000 evaluations, with remaining budget spent on local exploitation.

\textbf{F23 (N-Queens):} Similar pattern to LABS, with fast early progress and plateau behavior. This suggests the algorithm quickly finds the general structure but struggles with fine-tuning to eliminate final conflicts.

\textbf{F23 (Katsuura):} The ES shows initial improvement in the early evaluations but appears to converge to local optima relatively quickly, with fitness values plateauing around 7-9. The consistent results across runs (std=0.48) suggest the algorithm reliably finds similar-quality local optima but struggles to escape them despite self-adaptation.

\subsubsection{Hyperparameter Effectiveness}

The unified hyperparameters work well for both binary problems:
\begin{itemize}
    \item Low mutation rate (0.01) prevents excessive disruption while maintaining diversity
    \item High crossover rate (0.85) enables effective building block combination
    \item Tournament size of 5 provides strong but not excessive selection pressure
    \item Population size of 100 balances diversity with number of generations
\end{itemize}

The fact that these parameters achieve competitive results on two fundamentally different problems (LABS and N-Queens) validates our tuning approach.

\section{Discussion and Conclusion}\label{sec:dis&res}

\subsection{Main Findings}

This work successfully demonstrates the application of evolutionary algorithms to challenging optimization problems. Key conclusions include:

\begin{enumerate}[1)]
    \item \textbf{Unified hyperparameters are effective:} A single GA configuration ($\mu=100$, $p_m=0.01$, $p_c=0.85$, $k=5$) achieves good performance on both LABS and N-Queens, demonstrating robustness across problem types.

    \item \textbf{Tournament selection with $k=5$ balances exploration and exploitation:} The larger tournament size provides sufficient selection pressure for rapid convergence while maintaining population diversity to escape local optima.

    \item \textbf{Low mutation rates benefit binary optimization:} The mutation rate of 0.01 (close to theoretical $1/n$) allows fine-grained local search without excessive disruption, crucial for both LABS and N-Queens.

    \item \textbf{Self-adaptation alone is insufficient for difficult landscapes:} While the ES's self-adaptive step sizes eliminate manual tuning, the suboptimal results (mean 8.63) on Katsuura demonstrate that algorithm structure (population ratios, initial parameters) still critically impacts performance. Self-adaptation facilitates exploration but doesn't guarantee global optimization on highly irregular landscapes.

    \item \textbf{Comma selection enables self-adaptation but may limit convergence:} The $(\mu, \lambda)$ strategy facilitates self-adaptation by forcing progress through offspring, but may also prevent the algorithm from exploiting promising regions found by parents, potentially contributing to premature convergence to local optima.

    \item \textbf{Budget-constrained tuning is feasible:} Strategic sampling of the hyperparameter space with combined objectives successfully identifies effective configurations within limited evaluation budgets.
\end{enumerate}

\subsection{Algorithmic Insights}

\textbf{Genetic Algorithm:} The uniform crossover operator proved particularly effective for both LABS and N-Queens. Unlike one-point or two-point crossover, uniform crossover is position-independent and can better handle unknown epistatic structures \cite{spears1991}.

\textbf{Evolution Strategy:} The two-level learning rates ($\tau'$ and $\tau$) enable both global and coordinate-wise step size adaptation, which is theoretically important for non-separable functions. However, the poor performance (mean 8.63) suggests that either: (1) the initial step size ($\sigma_0=0.5$) was too large, causing overshooting, (2) the $\lambda/\mu$ ratio of 7:1 provided insufficient exploitation, or (3) the Katsuura landscape's extreme irregularity requires more sophisticated adaptation mechanisms like full covariance matrix adaptation (CMA-ES).

\subsection{Limitations}

Several limitations of this work should be noted:

\begin{itemize}
    \item \textbf{Limited budget:} 5,000 evaluations for GA and 50,000 for ES may be insufficient to reach global optima on these challenging problems
    \item \textbf{Single problem instances:} Testing only one instance per function limits generalizability
    \item \textbf{No perfect N-Queens solutions:} The GA did not achieve zero-conflict solutions within the budget
    \item \textbf{Tuning budget constraints:} Only 5 configurations could be thoroughly evaluated, potentially missing better parameter combinations
    \item \textbf{Poor ES convergence on Katsuura:} The ES achieved suboptimal results (mean fitness 8.63), suggesting the algorithm parameters or strategy may not be well-suited for this highly irregular landscape
\end{itemize}

\subsection{Future Work}

Potential improvements include:

\begin{itemize}
    \item \textbf{Adaptive parameter control:} Implement dynamic adjustment of mutation/crossover rates during evolution
    \item \textbf{Advanced ES variants:} Upgrade to CMA-ES \cite{hansen2001} for full covariance matrix adaptation
    \item \textbf{Hybrid approaches:} Combine GA with local search for N-Queens to eliminate final conflicts
    \item \textbf{Better tuning methods:} Apply Bayesian optimization or racing algorithms for more efficient hyperparameter search
    \item \textbf{Problem-specific operators:} Develop specialized operators for N-Queens (e.g., permutation encoding)
\end{itemize}

\subsection{Conclusion}

This assignment successfully implemented and evaluated two evolutionary algorithms on challenging benchmarks from discrete and continuous optimization. The Genetic Algorithm demonstrated ability to handle diverse binary problems with unified hyperparameters, achieving competitive results on both LABS (mean merit factor 4.03) and N-Queens (mean 6.1 conflicts) given the limited 5,000 evaluation budget.

The Evolution Strategy, while successfully implementing self-adaptive step sizes, achieved suboptimal results on the Katsuura function (mean fitness 8.63), highlighting the challenge of optimizing highly irregular, multimodal continuous landscapes. This underscores an important lesson: while self-adaptation provides parameter-free optimization, algorithm design choices (population size ratio, initial step sizes, selection strategy) still significantly impact performance and may require problem-specific tuning or more sophisticated variants like CMA-ES.

The results demonstrate both successes and limitations of evolutionary algorithms. The GA's robustness across problem types validates the hyperparameter tuning approach, while the ES's struggles emphasize that no single algorithm excels on all problems. The importance of appropriate operator selection, parameter tuning, and algorithm design choices is clearly demonstrated, as is the value of honest performance reporting and analysis.

\bibliographystyle{unsrt}
\bibliography{references}

\end{document}
